<h1 align="center">ğŸ’»â­ LLM Explorations</h1>

<p align="center">
  <img src="assets/cover.png" alt="Studying LLMs" width="200"/>
</p>

This repository is a **personal learning lab** dedicated to exploring **generative AI**, with a specific focus on **Large Language Models (LLMs)**.

It collects **Jupyter notebooks and Python scripts** developed while studying, testing, and critically analyzing how modern generative models behave across different tasks and settings.

---

## ğŸ¯ Goals

The main goal of this repository is **understanding**, not optimization.

Each experiment is designed to answer questions such as:
- What does this model actually learn?
- Why does a certain prompting strategy work (or fail)?
- What are the limitations of a given approach?
- How do different models behave on the same task?

Rather than maximizing performance, the focus is on **interpretability, awareness, and hands-on experimentation**.

---

## ğŸ“‚ Contents

The repository may include:

- ğŸ““ **Jupyter notebooks** for interactive experiments  
- ğŸ **Python scripts** for reusable components and pipelines  
- âœï¸ **Prompting experiments** (zero-shot, few-shot, structured prompts)  
- ğŸ” **Output analysis** and qualitative evaluation  
- ğŸ”§ **Initial adaptation experiments**, such as:
  - prompt-based task specialization  
  - lightweight fine-tuning or parameter-efficient approaches (when applicable)

---

## ğŸ§ª Topics Covered (evolving)

Examples of topics explored in this repo:
- Text generation and analysis
- Prompt engineering strategies
- Model comparison on the same task
- Failure cases and hallucinations
- Task framing and instruction design
- Early experiments on adapting models to specific tasks

The repository is **incremental and exploratory by design**.

---

## ğŸ“ Code Attribution & Learning Disclaimer

This repository contains a mix of:
- original code written by the author,
- code adapted or reimplemented from external sources,
- examples inspired by tutorials, documentation, books, and online resources used for learning purposes.

Whenever external ideas or code snippets are used, the goal is not direct reuse, but **understanding, experimentation, and adaptation**.

All content in this repository is part of an ongoing learning process and is shared for educational and exploratory purposes.


---

## ğŸ“š Background

This repository accompanies a broader study of:
- generative AI foundations,
- transformer-based architectures,
- and practical experimentation with modern LLM tooling.

---

## ğŸš€ Status

ğŸ§© Work in progress â€” continuously updated as new ideas, models, and questions emerge.
