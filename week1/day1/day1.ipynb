{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercise Objective\n",
    "\n",
    "The goal of this exercise is to build a **simple but complete pipeline** that combines:\n",
    "1. **Web scraping**, to collect textual content from a website\n",
    "2. **Large Language Models**, to process and summarize the extracted content\n",
    "\n",
    "More specifically, the workflow is:\n",
    "- fetch the raw content of a web page,\n",
    "- pass the content to an LLM through an API call,\n",
    "- select a model explicitly,\n",
    "- generate a concise and meaningful summary of the website.\n",
    "\n",
    "This exercise is not focused on performance optimization, but on understanding how different components (scraping, prompting, model selection, and output visualization) interact in a real-world generative AI scenario.\n"
   ],
   "id": "99e49abbaa06f855"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "from week1.scraper import fetch_website_contents"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ],
   "id": "d753f749f463028c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## A first call",
   "id": "343244797c5a2d71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Write a massage\n",
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "# The first call\n",
    "openai = OpenAI()\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-5-nano\", messages=messages)\n",
    "response.choices[0].message.content"
   ],
   "id": "ff1b82cc7ba78dc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Web Scraping: Collecting Website Content\n",
    "\n",
    "The first step of the pipeline consists in **retrieving textual data from a web page**.\n",
    "\n",
    "Web scraping allows us to transform unstructured HTML content into raw text that can be processed by a language model. At this stage, the goal is not perfect text cleaning, but rather obtaining a representative snapshot of the page content.\n",
    "\n",
    "This step highlights an important practical aspect:\n",
    "> Large Language Models do not access the web directly — they only operate on the text that we explicitly provide as input.\n"
   ],
   "id": "235a745b1df81c20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Let's try out this utility\n",
    "website_path = \"https://it.wikipedia.org/wiki/The_Walt_Disney_Company\"\n",
    "content = fetch_website_contents(website_path)\n",
    "print(content)"
   ],
   "id": "172134ab84d4861d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prompt Design: System Prompt vs User Prompt\n",
    "\n",
    "The interaction with the language model is driven by **two different types of prompts**:\n",
    "\n",
    "### System Prompt\n",
    "The system prompt defines **how the model should behave**.\n",
    "It sets global instructions such as:\n",
    "- the role of the model (e.g. assistant, analyst, summarizer),\n",
    "- the expected style of the response,\n",
    "- constraints on tone, length, or level of detail.\n",
    "\n",
    "In other words, the system prompt provides the **behavioral context** for the model.\n",
    "\n",
    "### User Prompt\n",
    "The user prompt represents the **starting point of the conversation**.\n",
    "It contains the actual request, such as:\n",
    "- what task to perform,\n",
    "- what content to analyze,\n",
    "- what output is expected.\n",
    "\n",
    "The user prompt is interpreted *within the boundaries established by the system prompt*.\n",
    "\n",
    "### Why this distinction matters\n",
    "Separating system and user prompts improves:\n",
    "- clarity of intent,\n",
    "- controllability of the model’s behavior,\n",
    "- reproducibility of results.\n",
    "\n",
    "This distinction is especially important when building structured or multi-step LLM applications.\n"
   ],
   "id": "1721341606a6a5d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the system prompt\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a snarky assistant that analyzes the contents of a website,\n",
    "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\"\n",
    "\n",
    "# Define the user prompt\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\n",
    "\"\"\""
   ],
   "id": "454ade8ba743e396",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
    "    ]"
   ],
   "id": "243454b79f00a4d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "messages_for(website_path)",
   "id": "28a7e5d3a67d00ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## LLM Interaction and Model Selection\n",
    "\n",
    "Once the content is collected and the prompts are defined, the next step is to **call the OpenAI API**.\n",
    "\n",
    "In this exercise, the model is explicitly selected rather than relying on defaults. This makes the interaction:\n",
    "- more transparent,\n",
    "- easier to compare across different models,\n",
    "- reproducible over time.\n",
    "\n",
    "The language model receives:\n",
    "- the system prompt (behavioral instructions),\n",
    "- the user prompt (task definition),\n",
    "- the scraped website content as input.\n",
    "\n",
    "The output is a synthesized summary generated by the model based on these inputs.\n"
   ],
   "id": "79f200d0f7e763b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "url_to_scrape = website_path",
   "id": "e237813d3fb2db31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Call the OpenAI API\n",
    "\n",
    "def summarize(url):\n",
    "    website = fetch_website_contents(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4.1-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ],
   "id": "7fa42c5ed67aa0b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Visualizing the Result\n",
    "\n",
    "The final output of the pipeline is the summary generated by the language model.\n",
    "\n",
    "Instead of printing plain text, the result is displayed using **Markdown rendering**, which improves readability and allows structured formatting (headings, bullet points, emphasis)."
   ],
   "id": "661787621551a561"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ],
   "id": "de8e8768cd8d9961",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "display_summary(url_to_scrape)",
   "id": "515b05537683433",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
